#+TAGS: clf reg

* General

These notes are largely based on the book Hands-on machine learning
with Scikit-Learn and TensorFlow, by Aurélien Géron.

** Types of machine learning systems

They can be classified in broad categories based on:

- Supervised, unsupervised, semisupervised, reinforcement learning

- Whether or not they can learn incrementally on the fly (online
  versus batch learning)

- Whether they work by simply compairing new data points to known data
  points, or instead detect patterns in the training data and build a
  predictive model, much like scientists do (instance-based versus
  model-based learning)

These criteria are not exclusive - you can combine them in any way you
like. 

*** Supervised learning

The training data includes the desired solutions, called "labels".

You use different scoring functions depending of whether you want to
use categorical or regression.

**** Categorical

The purpose is to divide the data into categories. Male / female, etc.

**** Regression

The purpose is the assign a value to each data point.

*** Unsupervised learning

The training data is unlabeled. The system tries to learn without a
teacher.

Some important unsupervised learning algorithms:

- Clustering
  - k-Means
  - Hierarchical Cluster Analysis (HCA)
  - Expectation Maximization
- Visualization and dimensionality reduction
  - Principal Component Analysis (PCA)
  - Kernel PCA
  - Locally-Linear Embedding (LLE)
  - t-Distributed Stochastic Neighbor Embedding (t-SNE)
- Association rule learning
  - Apriori
  - Eclat

*** Semisupervised learning

Deals with partially labeled data; usually most of it is unlabeled.
Google Photos is a good example. It recognizes the same people in many
photos, and you tell it who it is (you label it) in one of the
pictures. The system will realize that it's the same person in all
those photos.


*** Reinforcement learning

- AlphaGo.
- Robots trying to learn to walk on their own.
- The agent has to be able to figure out on its own if it should get
  good or bad reinforcement - if someone else is doing it (like with
  the creature in Black & White), it's not reinforcement learning.

*** Batch learning versus Online learning

This is another way of classifying learning systems.

**** Batch learning

In this mode, it can't learn with incomplete data - it needs all the
data at the same time. Also called offline learning.

First it is trained, then it is used. It doesn't learn while being
used. 

Since it needs all data when it learns (or relearns), it takes a long
time. This system is simple, and often good enough.

**** Online learning

Can learn incrementally with small batches of data, called "mini
batches". Each learning step is fast and cheap. It doesn't necessarily
have to happen on a running system though (while it is in use) - the
key feature of online learning is that it can learn incrementally.

"Learning rate" is how fast the system should adapt to new data. High
means adapt quickly.

*** Instance-based versus Model-based learning

**** Instance-based learning

Based on individual examples. Things are classified based on how
similar they are to already classified instances.

**** Model-based

Model-based makes predictions.

** Machine learning project checklist

1. Frame the problem and look at the big picture.

2. Get the data.

3. Explore the data to gain insights.

4. Preare the data to better expose the underlying data patterns to
   Machine Learning algorithms.

5. Explore many different models and short-list the best ones.

6. Fine-tune your models and combine them into a great solution.

7. Present your solution.

8. Launch, monistor and maintain your system.

** Equations and RMSE

RMSE = Root Mean Square Error, is a typical performance measure for
regression problems. You try to get as low a RMSE as possible.

The purpose of RMSE is a scoring function which focuses on the bigger
errors, since all errors are squared.

| Variable     | Explanation                                            |
|--------------+--------------------------------------------------------|
| m            | Number of instances in the dataset                     |
| x[upper (i)] | A vector of all the feature values excluding the label |
|              | of the i[upper th] and y[upper (i)] is its label.      |

* Algorithms

** Stochastic Gradient Descent classifier <<<SGD>>>                    :clf:

- Advantage: Handles large datasets efficiently.
- Note: It's random. Use random_state=42 argument to constructor
  to make it repeatable.

** K-nearest Neighbor <<<KNN>>>                                        :clf:

- Used for: Classification and regression.

** Support Vector Machines <<<SVM>>>                                   :clf:

- SVMs are supervised learning models.
- When labels aren't available, they rely on trying to find
  clusters of data, and consider new observations as belonging
  to one of these clusters.
- Scales poorly with the size of the training set, so with this
  one, probably use OvO rather than OvA.

*** Applications

- Helpful in text and hypertext categorization.
- Classification of images can be performed using SVMs.

** <<<Random Forest Classifiers>>>                                     :clf:

- Capable of handling more than two classes; IE, it is a
  multiclass classifier, not a binary classifier.


* Concepts

** <<<Precision>>> and <<<Recall>>>

** <<<Confusion matrix>>>

Confusion matrixes, also known as error matrixes, are used to
evaluate the performance of a classifier by displaying the
performance visually.

- Each row represents the instances in a predicted class.
- Each column represents the instances in an actual class (or
  vice versa).

*** Example

Across ----> Actual class

Down |
     | Predicted class
     V

|--------+-----+-----+--------|
|        | Cat | Dog | Rabbit |
|--------+-----+-----+--------|
| Cat    |   5 |   2 |      0 |
|--------+-----+-----+--------|
| Dog    |   3 |   3 |      2 |
|--------+-----+-----+--------|
| Rabbit |   0 |   1 |     11 |
|--------+-----+-----+--------|

- Of the 8 ACTUAL cats, the system predicted that 5 of them were
  cats, 3 dogs and no rabbits.
- Of the 7 PREDICTED cats, 2 were actually dogs and 5 were in
  fact cats.

** One vs One and One vs All

*** One vs One <<<OvO>>>

- One vs One is when you train a binary classifier to
  distinguish between 5 and 0, one between 5 and 1, one between
  5 and 2, etc.

*** One vs All <<<OvA>>>

- Preferred for most binary classifications algorithms.
- One vs All is when for each class, you have a binary
  classifier for each *pair*.
- If you have 10 classes (n = 10), you will need:
  - n * (n - 1) / 2 = 45 classifiers.

** Algorithm types

*** <<<Multilabel Classification Systems>>>

- Outputs zero or more classes for each instance. For example, a
  face recognizer should be able to spot more than one face in
  each photo.

* Scoring

** Root Mean Square Error <<<RMSE>>>

RMSE is a scoring function which focuses on the bigger errors,
since the scores are squared.

* Glossary

| Term       | Description                                                 |
|------------+-------------------------------------------------------------|
| Label      | A desired solution included in training data for supervised |
|            | learning.                                                   |
| Predictor  | For example, mileage, age and brand for cars could be       |
|            | "predictors" used to try to guesstimate a car's value.      |
| Attribute  | Data type (for example, "milage")                           |
| Feature    | Generally a an attribute plus its value.                    |
| Pipeline   | A sequence of data processing components.                   |
| RMSE       | Root Mean Square Error                                      |
| Hypothesis | Predictor function                                          |
| MAE        | Mean Absolute Error (outliers are more okay than w/ RMSE)   |
|            |                                                             |
